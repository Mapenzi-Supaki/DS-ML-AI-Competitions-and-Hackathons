{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "4b49dac480128e3353893aae5d79bc0c223b3b150e1bd621885640ef2984f829"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress FutureWarnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "\n",
    "#display the graphics made by python inline with the text\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "source": [
    "## Understand the Data with Descriptive Statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Check the shape and size of datasets\n",
    "train.shape, test.shape, submission.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((108446, 42), (46477, 41), (46477, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "#peek at the data\n",
    "train.tail()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ5  FQ6  \\\n",
       "108441  ID_ZZYY7RTO           111       4  23.0    2  NaN  NaN    2  NaN  2.0   \n",
       "108442  ID_ZZYZTTC6            77       4  60.0    1  NaN  NaN    2  NaN  NaN   \n",
       "108443  ID_ZZZ3OW3S            42       2  59.0    1  NaN  1.0    1  NaN  NaN   \n",
       "108444  ID_ZZZLDXE8            57       7  79.0    1  NaN  NaN    2  NaN  1.0   \n",
       "108445  ID_ZZZMYW1F           110       2  74.0    2  1.0  2.0    2  NaN  1.0   \n",
       "\n",
       "        ...  FQ27  FQ28  FQ29  FQ30  FQ31  FQ32  FQ33  FQ34  FQ37  Target  \n",
       "108441  ...   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN     1       0  \n",
       "108442  ...   NaN   NaN   NaN   NaN   NaN   NaN   1.0   1.0     1       0  \n",
       "108443  ...   NaN   NaN   2.0   NaN   NaN   2.0   1.0   2.0     1       1  \n",
       "108444  ...   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1       0  \n",
       "108445  ...   NaN   NaN   1.0   NaN   NaN   NaN   1.0   NaN     1       1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>...</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108441</th>\n      <td>ID_ZZYY7RTO</td>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>ID_ZZYZTTC6</td>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>ID_ZZZ3OW3S</td>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>ID_ZZZLDXE8</td>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>ID_ZZZMYW1F</td>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "source": [
    "#Look at first 5 records\n",
    "test.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ5  FQ6  ...  \\\n",
       "0  ID_000YI58E            39       2  22.0    2  NaN  NaN    2  NaN  1.0  ...   \n",
       "1  ID_001SP4JF            30       2  62.0    1  NaN  NaN    2  NaN  1.0  ...   \n",
       "2  ID_001VOF6S            65       4  35.0    2  1.0  NaN    1  1.0  NaN  ...   \n",
       "3  ID_0030LULG           123       0  24.0    2  1.0  NaN    2  NaN  1.0  ...   \n",
       "4  ID_0037PZ3R            67       2  25.0    2  NaN  NaN    1  NaN  NaN  ...   \n",
       "\n",
       "   FQ26  FQ27  FQ28  FQ29  FQ30  FQ31  FQ32  FQ33  FQ34  FQ37  \n",
       "0     2   NaN   NaN   NaN   NaN   NaN   2.0   1.0   1.0     0  \n",
       "1     2   NaN   NaN   2.0   NaN   1.0   1.0   1.0   1.0     0  \n",
       "2     2   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN     0  \n",
       "3     2   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "4     2   NaN   NaN   1.0   NaN   NaN   NaN   2.0   1.0     1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>...</th>\n      <th>FQ26</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>39</td>\n      <td>2</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>30</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>65</td>\n      <td>4</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>123</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>67</td>\n      <td>2</td>\n      <td>25.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "submission.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID  Target\n",
       "0  ID_000YI58E     NaN\n",
       "1  ID_001SP4JF     NaN\n",
       "2  ID_001VOF6S     NaN\n",
       "3  ID_0030LULG     NaN\n",
       "4  ID_0037PZ3R     NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "source": [
    "#Check the columns in the train dataset\n",
    "train.columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#data type and columns of each attribute\n",
    "train.info()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        country_code         region            age            FQ1  \\\n",
       "count  108446.000000  108446.000000  108124.000000  108446.000000   \n",
       "mean       68.544953       2.894242      41.857395       1.563294   \n",
       "std        41.529264       2.286505      17.876105       0.530077   \n",
       "min         0.000000      -1.000000      15.000000       1.000000   \n",
       "25%        33.000000       1.000000      27.000000       1.000000   \n",
       "50%        65.000000       3.000000      39.000000       2.000000   \n",
       "75%       105.000000       4.000000      55.000000       2.000000   \n",
       "max       143.000000       7.000000      99.000000       4.000000   \n",
       "\n",
       "                FQ2           FQ3            FQ4           FQ5           FQ6  \\\n",
       "count  49124.000000  46218.000000  108446.000000  21185.000000  60659.000000   \n",
       "mean       1.063716      1.299710       1.824622      1.160113      1.223907   \n",
       "std        0.288075      0.468503       0.435942      0.383827      0.450140   \n",
       "min        1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000       2.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000       2.000000      1.000000      1.000000   \n",
       "75%        1.000000      2.000000       2.000000      1.000000      1.000000   \n",
       "max        4.000000      4.000000       4.000000      4.000000      4.000000   \n",
       "\n",
       "                FQ7  ...         FQ27         FQ28          FQ29         FQ30  \\\n",
       "count  60620.000000  ...  3200.000000  1506.000000  83912.000000  2115.000000   \n",
       "mean       1.206961  ...     1.578125     1.351262      1.860330     1.615130   \n",
       "std        0.440780  ...     0.563689     0.493938      0.382599     0.548808   \n",
       "min        1.000000  ...     1.000000     1.000000      1.000000     1.000000   \n",
       "25%        1.000000  ...     1.000000     1.000000      2.000000     1.000000   \n",
       "50%        1.000000  ...     2.000000     1.000000      2.000000     2.000000   \n",
       "75%        1.000000  ...     2.000000     2.000000      2.000000     2.000000   \n",
       "max        4.000000  ...     4.000000     4.000000      4.000000     4.000000   \n",
       "\n",
       "             FQ31          FQ32           FQ33          FQ34           FQ37  \\\n",
       "count  869.000000  60796.000000  108444.000000  76652.000000  108446.000000   \n",
       "mean     1.436133      1.854744       1.178479      1.127511       0.631457   \n",
       "std      0.557423      0.401499       0.398819      0.350632       0.482412   \n",
       "min      1.000000      1.000000       1.000000      1.000000       0.000000   \n",
       "25%      1.000000      2.000000       1.000000      1.000000       0.000000   \n",
       "50%      1.000000      2.000000       1.000000      1.000000       1.000000   \n",
       "75%      2.000000      2.000000       1.000000      1.000000       1.000000   \n",
       "max      4.000000      4.000000       4.000000      4.000000       1.000000   \n",
       "\n",
       "              Target  \n",
       "count  108446.000000  \n",
       "mean        0.273970  \n",
       "std         0.445996  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>...</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>108446.000000</td>\n      <td>108446.000000</td>\n      <td>108124.000000</td>\n      <td>108446.000000</td>\n      <td>49124.000000</td>\n      <td>46218.000000</td>\n      <td>108446.000000</td>\n      <td>21185.000000</td>\n      <td>60659.000000</td>\n      <td>60620.000000</td>\n      <td>...</td>\n      <td>3200.000000</td>\n      <td>1506.000000</td>\n      <td>83912.000000</td>\n      <td>2115.000000</td>\n      <td>869.000000</td>\n      <td>60796.000000</td>\n      <td>108444.000000</td>\n      <td>76652.000000</td>\n      <td>108446.000000</td>\n      <td>108446.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>68.544953</td>\n      <td>2.894242</td>\n      <td>41.857395</td>\n      <td>1.563294</td>\n      <td>1.063716</td>\n      <td>1.299710</td>\n      <td>1.824622</td>\n      <td>1.160113</td>\n      <td>1.223907</td>\n      <td>1.206961</td>\n      <td>...</td>\n      <td>1.578125</td>\n      <td>1.351262</td>\n      <td>1.860330</td>\n      <td>1.615130</td>\n      <td>1.436133</td>\n      <td>1.854744</td>\n      <td>1.178479</td>\n      <td>1.127511</td>\n      <td>0.631457</td>\n      <td>0.273970</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>41.529264</td>\n      <td>2.286505</td>\n      <td>17.876105</td>\n      <td>0.530077</td>\n      <td>0.288075</td>\n      <td>0.468503</td>\n      <td>0.435942</td>\n      <td>0.383827</td>\n      <td>0.450140</td>\n      <td>0.440780</td>\n      <td>...</td>\n      <td>0.563689</td>\n      <td>0.493938</td>\n      <td>0.382599</td>\n      <td>0.548808</td>\n      <td>0.557423</td>\n      <td>0.401499</td>\n      <td>0.398819</td>\n      <td>0.350632</td>\n      <td>0.482412</td>\n      <td>0.445996</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>33.000000</td>\n      <td>1.000000</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>65.000000</td>\n      <td>3.000000</td>\n      <td>39.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>105.000000</td>\n      <td>4.000000</td>\n      <td>55.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>143.000000</td>\n      <td>7.000000</td>\n      <td>99.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#Statistical summary\n",
    "train.describe()"
   ]
  },
  {
   "source": [
    "#Examine distribution of the target column\n",
    "train['Target'].value_counts()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here:\n",
    "- 0: Did not use mobile or internet banking\n",
    "- 1: Used mobile or internet banking\n",
    "\n",
    "This shows that less people use moble or internet banking."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examine Missing & Duplicated Values\n",
    "Data\n",
    "There are also various ways to handle missing data:\n",
    " - Remove any row with missing data\n",
    " - Remove any column with missing data\n",
    " - Impute missing values\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Find duplicates\n",
    "train.duplicated().any()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "source": [
    "#train.isnull().any()\n",
    "\n",
    "#Counting the Number of Null rows in each Column of the dataframe\n",
    "train.isnull().sum()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Counting the Number of Null rows in each Column of the dataframe\n",
    "test.isnull().sum()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Subset\n",
    "target = train['target']\n",
    "train_id = train['id']\n",
    "test_id = test['id']\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "#Null values\n",
    "null_df = pd.DataFrame({'Percentile':train.isnull().sum()/len(train), 'Count':train.isnull().sum()})\n",
    "print(null_df)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Understand Your Data With Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Create a bar plot of % of missing data counts using pandas\n",
    "missing_values = train.isnull().sum() / len(train) *100 #in percentage\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values.sort_values(inplace=True)\n",
    "missing_values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "missing_values.index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "missing_values = missing_values.to_frame()\n",
    "missing_values.columns = ['count']\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.barplot(x = missing_values.index, y = 'count', data=missing_values)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "Columns with type of object tend to be categorical (but they may also be high cardinality string data, or a mix of column types). For object columns that we believe to be categorical, use the .value_counts method to examine the counts of the values:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">>> df.sex.value_counts(dropna=False)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Remember that pandas typically ignores null or NaN values. If you want to include those, use dropna=False to also show counts for NaN:\n",
    ">>> df.embarked.value_counts(dropna=False)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dealing with Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ID               0.000000\ncountry_code     0.000000\nregion           0.000000\nage              0.296922\nFQ1              0.000000\nFQ2             54.701879\nFQ3             57.381554\nFQ4              0.000000\nFQ5             80.464932\nFQ6             44.065249\nFQ7             44.101212\nFQ8              0.000000\nFQ9              0.000000\nFQ10             0.000000\nFQ11            22.656437\nFQ12             0.000000\nFQ13             0.000000\nFQ14             0.000000\nFQ15             0.000000\nFQ16             0.000000\nFQ17            89.536728\nFQ18             0.000000\nFQ19            43.714844\nFQ20            22.756948\nFQ21            22.716375\nFQ22             0.000000\nFQ23             0.000000\nFQ24            64.561164\nFQ35            76.127289\nFQ36            89.411320\nFQ25             0.000000\nFQ26             0.000000\nFQ27            97.049223\nFQ28            98.611290\nFQ29            22.623241\nFQ30            98.049721\nFQ31            99.198680\nFQ32            43.938919\nFQ33             0.001844\nFQ34            29.317817\nFQ37             0.000000\nTarget           0.000000\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Total missing values for each feature\n",
    "print (train.isnull().sum()/ len(train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Total    Percent\n",
       "FQ31  107577  99.198680\n",
       "FQ28  106940  98.611290\n",
       "FQ30  106331  98.049721\n",
       "FQ27  105246  97.049223\n",
       "FQ17   97099  89.536728\n",
       "FQ36   96963  89.411320\n",
       "FQ5    87261  80.464932\n",
       "FQ35   82557  76.127289\n",
       "FQ24   70014  64.561164\n",
       "FQ3    62228  57.381554\n",
       "FQ2    59322  54.701879\n",
       "FQ7    47826  44.101212\n",
       "FQ6    47787  44.065249\n",
       "FQ32   47650  43.938919\n",
       "FQ19   47407  43.714844\n",
       "FQ34   31794  29.317817\n",
       "FQ20   24679  22.756948\n",
       "FQ21   24635  22.716375\n",
       "FQ11   24570  22.656437\n",
       "FQ29   24534  22.623241"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FQ31</th>\n      <td>107577</td>\n      <td>99.198680</td>\n    </tr>\n    <tr>\n      <th>FQ28</th>\n      <td>106940</td>\n      <td>98.611290</td>\n    </tr>\n    <tr>\n      <th>FQ30</th>\n      <td>106331</td>\n      <td>98.049721</td>\n    </tr>\n    <tr>\n      <th>FQ27</th>\n      <td>105246</td>\n      <td>97.049223</td>\n    </tr>\n    <tr>\n      <th>FQ17</th>\n      <td>97099</td>\n      <td>89.536728</td>\n    </tr>\n    <tr>\n      <th>FQ36</th>\n      <td>96963</td>\n      <td>89.411320</td>\n    </tr>\n    <tr>\n      <th>FQ5</th>\n      <td>87261</td>\n      <td>80.464932</td>\n    </tr>\n    <tr>\n      <th>FQ35</th>\n      <td>82557</td>\n      <td>76.127289</td>\n    </tr>\n    <tr>\n      <th>FQ24</th>\n      <td>70014</td>\n      <td>64.561164</td>\n    </tr>\n    <tr>\n      <th>FQ3</th>\n      <td>62228</td>\n      <td>57.381554</td>\n    </tr>\n    <tr>\n      <th>FQ2</th>\n      <td>59322</td>\n      <td>54.701879</td>\n    </tr>\n    <tr>\n      <th>FQ7</th>\n      <td>47826</td>\n      <td>44.101212</td>\n    </tr>\n    <tr>\n      <th>FQ6</th>\n      <td>47787</td>\n      <td>44.065249</td>\n    </tr>\n    <tr>\n      <th>FQ32</th>\n      <td>47650</td>\n      <td>43.938919</td>\n    </tr>\n    <tr>\n      <th>FQ19</th>\n      <td>47407</td>\n      <td>43.714844</td>\n    </tr>\n    <tr>\n      <th>FQ34</th>\n      <td>31794</td>\n      <td>29.317817</td>\n    </tr>\n    <tr>\n      <th>FQ20</th>\n      <td>24679</td>\n      <td>22.756948</td>\n    </tr>\n    <tr>\n      <th>FQ21</th>\n      <td>24635</td>\n      <td>22.716375</td>\n    </tr>\n    <tr>\n      <th>FQ11</th>\n      <td>24570</td>\n      <td>22.656437</td>\n    </tr>\n    <tr>\n      <th>FQ29</th>\n      <td>24534</td>\n      <td>22.623241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent =total/len(train)*100\n",
    "pd.concat([total,percent], axis=1, keys=['Total','Percent']).head(20)"
   ]
  },
  {
   "source": [
    "Here you can clearly see that 7 columns have Null values higher than 80% so it is good to drop those columns from our data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ6  FQ7  \\\n",
       "0       ID_000J8GTZ             1       6  35.0    2  NaN  NaN    2  NaN  1.0   \n",
       "1       ID_000QLXZM            32       7  70.0    2  NaN  NaN    2  NaN  1.0   \n",
       "2       ID_001728I2            71       7  22.0    2  1.0  NaN    2  NaN  1.0   \n",
       "3       ID_001R7IDN            48       3  27.0    1  NaN  NaN    2  2.0  NaN   \n",
       "4       ID_0029QKF8            25       0  79.0    2  NaN  NaN    2  NaN  NaN   \n",
       "...             ...           ...     ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "108441  ID_ZZYY7RTO           111       4  23.0    2  NaN  NaN    2  2.0  NaN   \n",
       "108442  ID_ZZYZTTC6            77       4  60.0    1  NaN  NaN    2  NaN  NaN   \n",
       "108443  ID_ZZZ3OW3S            42       2  59.0    1  NaN  1.0    1  NaN  1.0   \n",
       "108444  ID_ZZZLDXE8            57       7  79.0    1  NaN  NaN    2  1.0  NaN   \n",
       "108445  ID_ZZZMYW1F           110       2  74.0    2  1.0  2.0    2  1.0  1.0   \n",
       "\n",
       "        ...  FQ24  FQ35  FQ25  FQ26  FQ29  FQ32  FQ33  FQ34  FQ37  Target  \n",
       "0       ...   NaN   1.0     2     2   1.0   NaN   1.0   1.0     0       0  \n",
       "1       ...   NaN   NaN     1     1   2.0   NaN   1.0   2.0     0       0  \n",
       "2       ...   NaN   NaN     2     1   2.0   NaN   2.0   1.0     1       0  \n",
       "3       ...   NaN   NaN     2     2   NaN   2.0   1.0   1.0     1       0  \n",
       "4       ...   2.0   NaN     2     2   2.0   2.0   1.0   1.0     1       0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...     ...  \n",
       "108441  ...   2.0   NaN     2     2   NaN   NaN   1.0   NaN     1       0  \n",
       "108442  ...   NaN   NaN     2     2   NaN   NaN   1.0   1.0     1       0  \n",
       "108443  ...   NaN   NaN     2     2   2.0   2.0   1.0   2.0     1       1  \n",
       "108444  ...   NaN   NaN     2     2   2.0   NaN   1.0   1.0     1       0  \n",
       "108445  ...   2.0   NaN     2     2   1.0   NaN   1.0   NaN     1       1  \n",
       "\n",
       "[108446 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>...</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000J8GTZ</td>\n      <td>1</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_000QLXZM</td>\n      <td>32</td>\n      <td>7</td>\n      <td>70.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001728I2</td>\n      <td>71</td>\n      <td>7</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_001R7IDN</td>\n      <td>48</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0029QKF8</td>\n      <td>25</td>\n      <td>0</td>\n      <td>79.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108441</th>\n      <td>ID_ZZYY7RTO</td>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>ID_ZZYZTTC6</td>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>ID_ZZZ3OW3S</td>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>ID_ZZZLDXE8</td>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>ID_ZZZMYW1F</td>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108446 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train = train [train.columns[train.isnull().mean() < 0.80]]\n",
    "train"
   ]
  },
  {
   "source": [
    "You can also drop specific rows with a higher number of missing values. This may increase the accuracy of your model rather than filling these columns. This is beneficial only when you have a large amount of data.\n",
    "\n",
    ">>> train.isnull().sum(axis=1).sort_values(ascending=False).head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Drop Rows of pandas DataFrame that Contain X or More Missing Values\n",
    "\n",
    "This example demonstrates how to remove rows from a data set that contain a certain amount of missing values.\n",
    "In the following example code, all rows with 2 or more NaN values are dropped:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ6  FQ7  \\\n",
       "0       ID_000J8GTZ             1       6  35.0    2  NaN  NaN    2  NaN  1.0   \n",
       "1       ID_000QLXZM            32       7  70.0    2  NaN  NaN    2  NaN  1.0   \n",
       "2       ID_001728I2            71       7  22.0    2  1.0  NaN    2  NaN  1.0   \n",
       "3       ID_001R7IDN            48       3  27.0    1  NaN  NaN    2  2.0  NaN   \n",
       "4       ID_0029QKF8            25       0  79.0    2  NaN  NaN    2  NaN  NaN   \n",
       "...             ...           ...     ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "108441  ID_ZZYY7RTO           111       4  23.0    2  NaN  NaN    2  2.0  NaN   \n",
       "108442  ID_ZZYZTTC6            77       4  60.0    1  NaN  NaN    2  NaN  NaN   \n",
       "108443  ID_ZZZ3OW3S            42       2  59.0    1  NaN  1.0    1  NaN  1.0   \n",
       "108444  ID_ZZZLDXE8            57       7  79.0    1  NaN  NaN    2  1.0  NaN   \n",
       "108445  ID_ZZZMYW1F           110       2  74.0    2  1.0  2.0    2  1.0  1.0   \n",
       "\n",
       "        ...  FQ24  FQ35  FQ25  FQ26  FQ29  FQ32  FQ33  FQ34  FQ37  Target  \n",
       "0       ...   NaN   1.0     2     2   1.0   NaN   1.0   1.0     0       0  \n",
       "1       ...   NaN   NaN     1     1   2.0   NaN   1.0   2.0     0       0  \n",
       "2       ...   NaN   NaN     2     1   2.0   NaN   2.0   1.0     1       0  \n",
       "3       ...   NaN   NaN     2     2   NaN   2.0   1.0   1.0     1       0  \n",
       "4       ...   2.0   NaN     2     2   2.0   2.0   1.0   1.0     1       0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...     ...  \n",
       "108441  ...   2.0   NaN     2     2   NaN   NaN   1.0   NaN     1       0  \n",
       "108442  ...   NaN   NaN     2     2   NaN   NaN   1.0   1.0     1       0  \n",
       "108443  ...   NaN   NaN     2     2   2.0   2.0   1.0   2.0     1       1  \n",
       "108444  ...   NaN   NaN     2     2   2.0   NaN   1.0   1.0     1       0  \n",
       "108445  ...   2.0   NaN     2     2   1.0   NaN   1.0   NaN     1       1  \n",
       "\n",
       "[108446 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>...</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000J8GTZ</td>\n      <td>1</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_000QLXZM</td>\n      <td>32</td>\n      <td>7</td>\n      <td>70.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001728I2</td>\n      <td>71</td>\n      <td>7</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_001R7IDN</td>\n      <td>48</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0029QKF8</td>\n      <td>25</td>\n      <td>0</td>\n      <td>79.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108441</th>\n      <td>ID_ZZYY7RTO</td>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>ID_ZZYZTTC6</td>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>ID_ZZZ3OW3S</td>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>ID_ZZZLDXE8</td>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>ID_ZZZMYW1F</td>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108446 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train = train.dropna(thresh = 2)                # Apply dropna() function\n",
    "train"
   ]
  },
  {
   "source": [
    "import missingno as msno\n",
    "msno.matrix(train, inline=True, sparkline=True, figsize=(20,10), sort='ascending', fontsize=12, labels=True, color=(0.30, 0.15, 0.43))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                  0\n",
       "country_code        0\n",
       "region              0\n",
       "age               322\n",
       "FQ1                 0\n",
       "FQ2             59322\n",
       "FQ3             62228\n",
       "FQ4                 0\n",
       "FQ6             47787\n",
       "FQ7             47826\n",
       "FQ8                 0\n",
       "FQ9                 0\n",
       "FQ10                0\n",
       "FQ11            24570\n",
       "FQ12                0\n",
       "FQ13                0\n",
       "FQ14                0\n",
       "FQ15                0\n",
       "FQ16                0\n",
       "FQ18                0\n",
       "FQ19            47407\n",
       "FQ20            24679\n",
       "FQ21            24635\n",
       "FQ22                0\n",
       "FQ23                0\n",
       "FQ24            70014\n",
       "FQ35            82557\n",
       "FQ25                0\n",
       "FQ26                0\n",
       "FQ29            24534\n",
       "FQ32            47650\n",
       "FQ33                2\n",
       "FQ34            31794\n",
       "FQ37                0\n",
       "Target              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                  0\n",
       "country_code        0\n",
       "region              0\n",
       "age               322\n",
       "FQ1                 0\n",
       "FQ2             59321\n",
       "FQ3             62228\n",
       "FQ4                 0\n",
       "FQ6             47786\n",
       "FQ7             47825\n",
       "FQ8                 0\n",
       "FQ9                 0\n",
       "FQ10                0\n",
       "FQ11            24569\n",
       "FQ12                0\n",
       "FQ13                0\n",
       "FQ14                0\n",
       "FQ15                0\n",
       "FQ16                0\n",
       "FQ18                0\n",
       "FQ19            47406\n",
       "FQ20            24679\n",
       "FQ21            24635\n",
       "FQ22                0\n",
       "FQ23                0\n",
       "FQ24            70013\n",
       "FQ35            82556\n",
       "FQ25                0\n",
       "FQ26                0\n",
       "FQ29            24533\n",
       "FQ32            47649\n",
       "FQ33                0\n",
       "FQ34            31794\n",
       "FQ37                0\n",
       "Target              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train.dropna(subset = ['FQ33'], axis = 0, how = 'any', inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ6  FQ7  FQ8  ...  \\\n",
       "0                  1       6  35.0    2  NaN  NaN    2  NaN  1.0    2  ...   \n",
       "1                 32       7  70.0    2  NaN  NaN    2  NaN  1.0    2  ...   \n",
       "2                 71       7  22.0    2  1.0  NaN    2  NaN  1.0    2  ...   \n",
       "3                 48       3  27.0    1  NaN  NaN    2  2.0  NaN    2  ...   \n",
       "4                 25       0  79.0    2  NaN  NaN    2  NaN  NaN    2  ...   \n",
       "...              ...     ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "108441           111       4  23.0    2  NaN  NaN    2  2.0  NaN    1  ...   \n",
       "108442            77       4  60.0    1  NaN  NaN    2  NaN  NaN    2  ...   \n",
       "108443            42       2  59.0    1  NaN  1.0    1  NaN  1.0    2  ...   \n",
       "108444            57       7  79.0    1  NaN  NaN    2  1.0  NaN    2  ...   \n",
       "108445           110       2  74.0    2  1.0  2.0    2  1.0  1.0    2  ...   \n",
       "\n",
       "        FQ23  FQ24  FQ35  FQ25  FQ26  FQ29  FQ32  FQ33  FQ34  FQ37  \n",
       "0          2   NaN   1.0     2     2   1.0   NaN   1.0   1.0     0  \n",
       "1          2   NaN   NaN     1     1   2.0   NaN   1.0   2.0     0  \n",
       "2          2   NaN   NaN     2     1   2.0   NaN   2.0   1.0     1  \n",
       "3          2   NaN   NaN     2     2   NaN   2.0   1.0   1.0     1  \n",
       "4          1   2.0   NaN     2     2   2.0   2.0   1.0   1.0     1  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "108441     2   2.0   NaN     2     2   NaN   NaN   1.0   NaN     1  \n",
       "108442     2   NaN   NaN     2     2   NaN   NaN   1.0   1.0     1  \n",
       "108443     2   NaN   NaN     2     2   2.0   2.0   1.0   2.0     1  \n",
       "108444     2   NaN   NaN     2     2   2.0   NaN   1.0   1.0     1  \n",
       "108445     2   2.0   NaN     2     2   1.0   NaN   1.0   NaN     1  \n",
       "\n",
       "[108444 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>FQ8</th>\n      <th>...</th>\n      <th>FQ23</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32</td>\n      <td>7</td>\n      <td>70.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71</td>\n      <td>7</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>0</td>\n      <td>79.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108441</th>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108444 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X = train.drop(['ID','Target'], axis = 1)\n",
    "y = train['Target']\n",
    "\n",
    "X"
   ]
  },
  {
   "source": [
    "test = test.drop(['ID', 'FQ5', 'FQ17', 'FQ36', 'FQ27', 'FQ28', 'FQ30', 'FQ31'], axis= 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['ID', 'FQ5', 'FQ17', 'FQ36', 'FQ27', 'FQ28', 'FQ30', 'FQ31'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   country_code  region       age       FQ1  FQ2  FQ3       FQ4       FQ6  \\\n",
       "0      0.006993   0.875  0.238095  0.333333  NaN  NaN  0.333333       NaN   \n",
       "1      0.223776   1.000  0.654762  0.333333  NaN  NaN  0.333333       NaN   \n",
       "2      0.496503   1.000  0.083333  0.333333  0.0  NaN  0.333333       NaN   \n",
       "3      0.335664   0.500  0.142857  0.000000  NaN  NaN  0.333333  0.333333   \n",
       "4      0.174825   0.125  0.761905  0.333333  NaN  NaN  0.333333       NaN   \n",
       "\n",
       "   FQ7       FQ8  ...      FQ23      FQ24  FQ35      FQ25      FQ26      FQ29  \\\n",
       "0  0.0  0.333333  ...  0.333333       NaN   0.0  0.333333  0.333333  0.000000   \n",
       "1  0.0  0.333333  ...  0.333333       NaN   NaN  0.000000  0.000000  0.333333   \n",
       "2  0.0  0.333333  ...  0.333333       NaN   NaN  0.333333  0.000000  0.333333   \n",
       "3  NaN  0.333333  ...  0.333333       NaN   NaN  0.333333  0.333333       NaN   \n",
       "4  NaN  0.333333  ...  0.000000  0.333333   NaN  0.333333  0.333333  0.333333   \n",
       "\n",
       "       FQ32      FQ33      FQ34  FQ37  \n",
       "0       NaN  0.000000  0.000000   0.0  \n",
       "1       NaN  0.000000  0.333333   0.0  \n",
       "2       NaN  0.333333  0.000000   1.0  \n",
       "3  0.333333  0.000000  0.000000   1.0  \n",
       "4  0.333333  0.000000  0.000000   1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>FQ8</th>\n      <th>...</th>\n      <th>FQ23</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.006993</td>\n      <td>0.875</td>\n      <td>0.238095</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.223776</td>\n      <td>1.000</td>\n      <td>0.654762</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.496503</td>\n      <td>1.000</td>\n      <td>0.083333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.335664</td>\n      <td>0.500</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.174825</td>\n      <td>0.125</td>\n      <td>0.761905</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "X.head()"
   ]
  },
  {
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "#define imputer\n",
    "imputer = IterativeImputer()\n",
    "#fit on the dataset\n",
    "imputer.fit(X)\n",
    "#transform the dataset\n",
    "X_imputed = imputer.transform(X)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error from Imputation:\n[[0.23076923 0.125      0.05952381 ... 0.         0.04217813 1.        ]\n [0.36363636 0.25       0.07142857 ... 0.         0.         1.        ]\n [0.26573427 0.125      0.23809524 ... 0.         0.04217813 1.        ]\n ...\n [0.42657343 0.375      0.48809524 ... 0.         0.         0.        ]\n [0.22377622 0.875      0.1547619  ... 0.         0.04217813 1.        ]\n [0.77622378 0.125      0.26190476 ... 0.         0.04217813 1.        ]] [[0.09090909 0.75       0.39285714 ... 0.         0.04217813 0.        ]\n [0.90909091 0.625      0.27380952 ... 0.33333333 0.         0.        ]\n [0.94405594 0.875      0.39285714 ... 0.         0.33333333 0.        ]\n ...\n [0.16083916 0.875      0.20238095 ... 0.         0.04217813 0.        ]\n [0.34265734 0.625      0.27380952 ... 0.         0.         1.        ]\n [0.40559441 0.125      0.28571429 ... 0.33333333 0.         1.        ]] 103659    0\n38423     0\n26218     0\n68988     0\n19628     1\n         ..\n106723    0\n5832      0\n82403     1\n78173     0\n95682     0\nName: Target, Length: 86755, dtype: int64 14092     0\n57463     0\n82629     0\n37109     1\n39959     1\n         ..\n74030     0\n44015     0\n104025    0\n56272     1\n102599    0\nName: Target, Length: 21689, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(imputed_X_train, imputed_X_test, y_train, y_test)"
   ]
  },
  {
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "#define imputer\n",
    "imputer = IterativeImputer()\n",
    "#fit on the dataset\n",
    "imputer.fit(X_train)\n",
    "#transform the dataset\n",
    "X_trainB = imputer.transform(X_train)\n",
    "X_testB = imputer.transform(X_test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Itlearns about the data and does nothing else\n",
    "my_imputer.fit(X_train)\n",
    "\n",
    "#Calling transform to apply the learnt information on supplied data\n",
    "X_train_new = my_imputer.transform(X_train)\n",
    "X_test_new = my_imputer.transform(X_test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "\n",
    "\n",
    "X_imputed = imputer.fit_transform(dfstd['marks'].values.reshape(-1,1))[:,0]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X = pd.DataFrame(imputer.fit_transform(X),columns = X.columns)\n",
    "X.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Initialize KNNImputer\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "#Impute/Fill Missing values of each feature\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform (X_train, y_train),  columns= X.columns)\n",
    "\n",
    "results = imputer.transform (X_test)\n",
    "\n",
    "results.shape\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Initialize KNNImputer\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "#Impute/Fill Missing values of each feature\n",
    "X_imputed = imputer.fit_transform (X)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(imputed_X_train, y_train)\n",
    "y_pred = clf.predict(imputed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ID', 'Target'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "array length 21689 does not match index length 46477",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5b528d0b48ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m submission_df = pd.DataFrame({\n\u001b[0m\u001b[0;32m      3\u001b[0m                   \u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \"Target\": y_pred})\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    409\u001b[0m                         \u001b[1;34mf\"length {len(index)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                     )\n\u001b[1;32m--> 411\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array length 21689 does not match index length 46477"
     ]
    }
   ],
   "source": [
    "ID = test['ID']\n",
    "submission_df = pd.DataFrame({\n",
    "                  \"ID\": ID, \n",
    "                  \"Target\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_1.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor()\n",
    "xgbr = xgbr.fit(X, y)\n",
    "pred_values = xgbr.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model = dt_model.fit (X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model score: %.3f\" % dt_model.score(X_testB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "predicted_proba = dt_model.predict_proba(X_testB)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = f1_score(y_test, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= dt_model.predict(X_testB)\n",
    "print('Score', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= dt_model.predict(X_testB)\n",
    "print('Score', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "predicted_proba = dt_model.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = f1_score(y_test, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= rf.predict(val_x)\n",
    "print('Score', f1_score(val_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = clf.predict (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['ID', 'FQ5', 'FQ17', 'FQ36', 'FQ27', 'FQ28', 'FQ30', 'FQ31'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "rf_model.fit(X_imputed, y)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ID': test.ID, 'Target': y_pred})\n",
    "output.to_csv('submission_RF2.csv', index=False)"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "train.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imputing Missing Data Using Sklearn SimpleImputer\n",
    "SimpleImputer is a class found in package sklearn.impute. It is used to impute / replace the numerical or categorical missing data related to one or more features with appropriate values. \n",
    "https://dzone.com/articles/imputing-missing-data-using-sklearn-simpleimputer\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There are two columns / features (one numerical - marks, and another categorical - gender) which are having missing values and need to be imputed. In the code below, an instance of SimpleImputer is created with strategy as \"mean\". The missing value is represented using NaN. Note some of the following:\n",
    "\n",
    "sklearn.impute package is used for importing SimpleImputer class.\n",
    "SimpleImputer takes two argument such as missing_values and strategy.\n",
    "fit_transform method is invoked on the instance of SimpleImputer to impute the missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imputation Approach with KNNImputer\n",
    "We will use the KNNImputer function from the impute module of the sklearn. KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#KNN based imputation for categorical variables\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "\n",
    "imputed_train = imputer.fit_transform(train[['country_code', 'region', 'age', 'FQ1', 'FQ2', 'FQ3', 'FQ4','FQ5', 'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13','FQ14', 'FQ15', 'FQ16', 'FQ17', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22','FQ23', 'FQ24', 'FQ35', 'FQ36', 'FQ25', 'FQ26', 'FQ27', 'FQ28', 'FQ29','FQ30', 'FQ31', 'FQ32', 'FQ33', 'FQ34', 'FQ37']])\n",
    "\n",
    "#print the completed dataframe\n",
    "imputed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "  \n",
    "# Imputer object using the mean strategy and \n",
    "# missing_values type for imputation\n",
    "imputer = SimpleImputer(missing_values = np.nan, \n",
    "                        strategy ='mean')\n",
    "  \n",
    "# Fitting the data to the imputer object\n",
    "imputer = imputer.fit(train)\n",
    "  \n",
    "# Imputing the data     \n",
    "imputed_train = imputer.transform(train)\n",
    "  \n",
    "print(\"Imputed Data : \\n\", imputed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Missing values is represented using NaN and hence specified. If it is empty field, missing values will be specified as:\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "\n",
    "dfstd.marks = imputer.fit_transform(dfstd['marks'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "dfstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "To drop all rows with 'any' NAs in a particular column, I used .dropna() and specified the subset = column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset = ['FQ33'], axis = 0, how = 'any', inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=\"cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Distribution\n",
    "target_counts = train.groupby('Target').size()\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "You can see that there are nearly triple the number of observations with target 0 than there are with target 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examine Target Column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sns.countplot(x = 'Target',data = train)\n",
    "sizes=[]\n",
    "for p in s.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    s.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/len(train)*100),\n",
    "            ha=\"center\", fontsize=14) "
   ]
  },
  {
   "source": [
    "## Create Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "sns.pairplot(train, hue='Target', size=1.5);"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first three rows\n",
    "train.iloc[1:4]"
   ]
  },
  {
   "source": [
    "## Replace Multiple Values in Multiple Columns\n",
    "\n",
    "Target Category:\n",
    "- 1: Yes\n",
    "- 2: No\n",
    "- 3: Don’t know \n",
    "- 4: Refused to answer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.count()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.replace({'FQ1': {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ2' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ3' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ4' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ5' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ6'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ7' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ8' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ9' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ10' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ11'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ12' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ13'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ14' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ15' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ16' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ17' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ18' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ19' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ20' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ21' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ22' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ23' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ24' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ35' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ36'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ25'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ26' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ27' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ28' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ29' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ30'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ31' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ32' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ33' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ34' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ37' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}})"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.columns"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique values\n",
    "train['country_code'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, value_counts will display all unique values with the number of times each value appears:\n",
    "# Show counts\n",
    "train['country_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique values\n",
    "train['region'].value_counts()"
   ]
  },
  {
   "source": [
    "Both unique and value_counts are useful for manipulating and exploring categorical\n",
    "columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FQ1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FQ4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change multiple columns with float to int\n",
    "train[['FQ1', 'FQ2', 'FQ3', 'FQ4',\n",
    "       'FQ5', 'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13',\n",
    "       'FQ14', 'FQ15', 'FQ16', 'FQ17', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22',\n",
    "       'FQ23', 'FQ24', 'FQ35', 'FQ36', 'FQ25', 'FQ26', 'FQ27', 'FQ28', 'FQ29',\n",
    "       'FQ30', 'FQ31', 'FQ32', 'FQ33', 'FQ34', 'FQ37']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}