{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "4b49dac480128e3353893aae5d79bc0c223b3b150e1bd621885640ef2984f829"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress FutureWarnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "\n",
    "#display the graphics made by python inline with the text\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "source": [
    "## Understand the Data with Descriptive Statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Check the shape and size of datasets\n",
    "train.shape, test.shape, submission.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((108446, 42), (46477, 41), (46477, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "#peek at the data\n",
    "train.tail()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ5  FQ6  \\\n",
       "108441  ID_ZZYY7RTO           111       4  23.0    2  NaN  NaN    2  NaN  2.0   \n",
       "108442  ID_ZZYZTTC6            77       4  60.0    1  NaN  NaN    2  NaN  NaN   \n",
       "108443  ID_ZZZ3OW3S            42       2  59.0    1  NaN  1.0    1  NaN  NaN   \n",
       "108444  ID_ZZZLDXE8            57       7  79.0    1  NaN  NaN    2  NaN  1.0   \n",
       "108445  ID_ZZZMYW1F           110       2  74.0    2  1.0  2.0    2  NaN  1.0   \n",
       "\n",
       "        ...  FQ27  FQ28  FQ29  FQ30  FQ31  FQ32  FQ33  FQ34  FQ37  Target  \n",
       "108441  ...   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN     1       0  \n",
       "108442  ...   NaN   NaN   NaN   NaN   NaN   NaN   1.0   1.0     1       0  \n",
       "108443  ...   NaN   NaN   2.0   NaN   NaN   2.0   1.0   2.0     1       1  \n",
       "108444  ...   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1       0  \n",
       "108445  ...   NaN   NaN   1.0   NaN   NaN   NaN   1.0   NaN     1       1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>...</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108441</th>\n      <td>ID_ZZYY7RTO</td>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>ID_ZZYZTTC6</td>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>ID_ZZZ3OW3S</td>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>ID_ZZZLDXE8</td>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>ID_ZZZMYW1F</td>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "source": [
    "#Look at first 5 records\n",
    "test.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ5  FQ6  ...  \\\n",
       "0  ID_000YI58E            39       2  22.0    2  NaN  NaN    2  NaN  1.0  ...   \n",
       "1  ID_001SP4JF            30       2  62.0    1  NaN  NaN    2  NaN  1.0  ...   \n",
       "2  ID_001VOF6S            65       4  35.0    2  1.0  NaN    1  1.0  NaN  ...   \n",
       "3  ID_0030LULG           123       0  24.0    2  1.0  NaN    2  NaN  1.0  ...   \n",
       "4  ID_0037PZ3R            67       2  25.0    2  NaN  NaN    1  NaN  NaN  ...   \n",
       "\n",
       "   FQ26  FQ27  FQ28  FQ29  FQ30  FQ31  FQ32  FQ33  FQ34  FQ37  \n",
       "0     2   NaN   NaN   NaN   NaN   NaN   2.0   1.0   1.0     0  \n",
       "1     2   NaN   NaN   2.0   NaN   1.0   1.0   1.0   1.0     0  \n",
       "2     2   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN     0  \n",
       "3     2   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "4     2   NaN   NaN   1.0   NaN   NaN   NaN   2.0   1.0     1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>...</th>\n      <th>FQ26</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>39</td>\n      <td>2</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>30</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>65</td>\n      <td>4</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>123</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>67</td>\n      <td>2</td>\n      <td>25.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "submission.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID  Target\n",
       "0  ID_000YI58E     NaN\n",
       "1  ID_001SP4JF     NaN\n",
       "2  ID_001VOF6S     NaN\n",
       "3  ID_0030LULG     NaN\n",
       "4  ID_0037PZ3R     NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        country_code         region            age            FQ1  \\\n",
       "count  108446.000000  108446.000000  108124.000000  108446.000000   \n",
       "mean       68.544953       2.894242      41.857395       1.563294   \n",
       "std        41.529264       2.286505      17.876105       0.530077   \n",
       "min         0.000000      -1.000000      15.000000       1.000000   \n",
       "25%        33.000000       1.000000      27.000000       1.000000   \n",
       "50%        65.000000       3.000000      39.000000       2.000000   \n",
       "75%       105.000000       4.000000      55.000000       2.000000   \n",
       "max       143.000000       7.000000      99.000000       4.000000   \n",
       "\n",
       "                FQ2           FQ3            FQ4           FQ5           FQ6  \\\n",
       "count  49124.000000  46218.000000  108446.000000  21185.000000  60659.000000   \n",
       "mean       1.063716      1.299710       1.824622      1.160113      1.223907   \n",
       "std        0.288075      0.468503       0.435942      0.383827      0.450140   \n",
       "min        1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000       2.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000       2.000000      1.000000      1.000000   \n",
       "75%        1.000000      2.000000       2.000000      1.000000      1.000000   \n",
       "max        4.000000      4.000000       4.000000      4.000000      4.000000   \n",
       "\n",
       "                FQ7  ...         FQ27         FQ28          FQ29         FQ30  \\\n",
       "count  60620.000000  ...  3200.000000  1506.000000  83912.000000  2115.000000   \n",
       "mean       1.206961  ...     1.578125     1.351262      1.860330     1.615130   \n",
       "std        0.440780  ...     0.563689     0.493938      0.382599     0.548808   \n",
       "min        1.000000  ...     1.000000     1.000000      1.000000     1.000000   \n",
       "25%        1.000000  ...     1.000000     1.000000      2.000000     1.000000   \n",
       "50%        1.000000  ...     2.000000     1.000000      2.000000     2.000000   \n",
       "75%        1.000000  ...     2.000000     2.000000      2.000000     2.000000   \n",
       "max        4.000000  ...     4.000000     4.000000      4.000000     4.000000   \n",
       "\n",
       "             FQ31          FQ32           FQ33          FQ34           FQ37  \\\n",
       "count  869.000000  60796.000000  108444.000000  76652.000000  108446.000000   \n",
       "mean     1.436133      1.854744       1.178479      1.127511       0.631457   \n",
       "std      0.557423      0.401499       0.398819      0.350632       0.482412   \n",
       "min      1.000000      1.000000       1.000000      1.000000       0.000000   \n",
       "25%      1.000000      2.000000       1.000000      1.000000       0.000000   \n",
       "50%      1.000000      2.000000       1.000000      1.000000       1.000000   \n",
       "75%      2.000000      2.000000       1.000000      1.000000       1.000000   \n",
       "max      4.000000      4.000000       4.000000      4.000000       1.000000   \n",
       "\n",
       "              Target  \n",
       "count  108446.000000  \n",
       "mean        0.273970  \n",
       "std         0.445996  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>...</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>108446.000000</td>\n      <td>108446.000000</td>\n      <td>108124.000000</td>\n      <td>108446.000000</td>\n      <td>49124.000000</td>\n      <td>46218.000000</td>\n      <td>108446.000000</td>\n      <td>21185.000000</td>\n      <td>60659.000000</td>\n      <td>60620.000000</td>\n      <td>...</td>\n      <td>3200.000000</td>\n      <td>1506.000000</td>\n      <td>83912.000000</td>\n      <td>2115.000000</td>\n      <td>869.000000</td>\n      <td>60796.000000</td>\n      <td>108444.000000</td>\n      <td>76652.000000</td>\n      <td>108446.000000</td>\n      <td>108446.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>68.544953</td>\n      <td>2.894242</td>\n      <td>41.857395</td>\n      <td>1.563294</td>\n      <td>1.063716</td>\n      <td>1.299710</td>\n      <td>1.824622</td>\n      <td>1.160113</td>\n      <td>1.223907</td>\n      <td>1.206961</td>\n      <td>...</td>\n      <td>1.578125</td>\n      <td>1.351262</td>\n      <td>1.860330</td>\n      <td>1.615130</td>\n      <td>1.436133</td>\n      <td>1.854744</td>\n      <td>1.178479</td>\n      <td>1.127511</td>\n      <td>0.631457</td>\n      <td>0.273970</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>41.529264</td>\n      <td>2.286505</td>\n      <td>17.876105</td>\n      <td>0.530077</td>\n      <td>0.288075</td>\n      <td>0.468503</td>\n      <td>0.435942</td>\n      <td>0.383827</td>\n      <td>0.450140</td>\n      <td>0.440780</td>\n      <td>...</td>\n      <td>0.563689</td>\n      <td>0.493938</td>\n      <td>0.382599</td>\n      <td>0.548808</td>\n      <td>0.557423</td>\n      <td>0.401499</td>\n      <td>0.398819</td>\n      <td>0.350632</td>\n      <td>0.482412</td>\n      <td>0.445996</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>33.000000</td>\n      <td>1.000000</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>65.000000</td>\n      <td>3.000000</td>\n      <td>39.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>105.000000</td>\n      <td>4.000000</td>\n      <td>55.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>143.000000</td>\n      <td>7.000000</td>\n      <td>99.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#Statistical summary\n",
    "train.describe()"
   ]
  },
  {
   "source": [
    "Here:\n",
    "- 0: Did not use mobile or internet banking\n",
    "- 1: Used mobile or internet banking\n",
    "\n",
    "This shows that less people use moble or internet banking."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examine Missing & Duplicated Values\n",
    "Data\n",
    "There are also various ways to handle missing data:\n",
    " - Remove any row with missing data\n",
    " - Remove any column with missing data\n",
    " - Impute missing values\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Duplicated values in data sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Find duplicates\n",
    "train.duplicated().any()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "test.duplicated().any()"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Counting the Number of Null rows in each Column of the dataframe\n",
    "train.isnull().sum()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                   0\n",
       "country_code         0\n",
       "region               0\n",
       "age                322\n",
       "FQ1                  0\n",
       "FQ2              59322\n",
       "FQ3              62228\n",
       "FQ4                  0\n",
       "FQ5              87261\n",
       "FQ6              47787\n",
       "FQ7              47826\n",
       "FQ8                  0\n",
       "FQ9                  0\n",
       "FQ10                 0\n",
       "FQ11             24570\n",
       "FQ12                 0\n",
       "FQ13                 0\n",
       "FQ14                 0\n",
       "FQ15                 0\n",
       "FQ16                 0\n",
       "FQ17             97099\n",
       "FQ18                 0\n",
       "FQ19             47407\n",
       "FQ20             24679\n",
       "FQ21             24635\n",
       "FQ22                 0\n",
       "FQ23                 0\n",
       "FQ24             70014\n",
       "FQ35             82557\n",
       "FQ36             96963\n",
       "FQ25                 0\n",
       "FQ26                 0\n",
       "FQ27            105246\n",
       "FQ28            106940\n",
       "FQ29             24534\n",
       "FQ30            106331\n",
       "FQ31            107577\n",
       "FQ32             47650\n",
       "FQ33                 2\n",
       "FQ34             31794\n",
       "FQ37                 0\n",
       "Target               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "source": [
    "#Counting the Number of Null rows in each Column of the dataframe\n",
    "test.isnull().sum()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                  0\n",
       "country_code        0\n",
       "region              0\n",
       "age               129\n",
       "FQ1                 0\n",
       "FQ2             25676\n",
       "FQ3             26549\n",
       "FQ4                 0\n",
       "FQ5             37564\n",
       "FQ6             20599\n",
       "FQ7             20560\n",
       "FQ8                 0\n",
       "FQ9                 0\n",
       "FQ10                0\n",
       "FQ11            10565\n",
       "FQ12                0\n",
       "FQ13                0\n",
       "FQ14                0\n",
       "FQ15                0\n",
       "FQ16                0\n",
       "FQ17            41599\n",
       "FQ18                0\n",
       "FQ19            20357\n",
       "FQ20            10456\n",
       "FQ21            10500\n",
       "FQ22                0\n",
       "FQ23                0\n",
       "FQ24            29912\n",
       "FQ35            35425\n",
       "FQ36            41577\n",
       "FQ25                0\n",
       "FQ26                0\n",
       "FQ27            45034\n",
       "FQ28            45846\n",
       "FQ29            10601\n",
       "FQ30            45601\n",
       "FQ31            46113\n",
       "FQ32            20477\n",
       "FQ33                0\n",
       "FQ34            13341\n",
       "FQ37                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "source": [
    "## Dealing with Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ID               0.000000\ncountry_code     0.000000\nregion           0.000000\nage              0.296922\nFQ1              0.000000\nFQ2             54.701879\nFQ3             57.381554\nFQ4              0.000000\nFQ5             80.464932\nFQ6             44.065249\nFQ7             44.101212\nFQ8              0.000000\nFQ9              0.000000\nFQ10             0.000000\nFQ11            22.656437\nFQ12             0.000000\nFQ13             0.000000\nFQ14             0.000000\nFQ15             0.000000\nFQ16             0.000000\nFQ17            89.536728\nFQ18             0.000000\nFQ19            43.714844\nFQ20            22.756948\nFQ21            22.716375\nFQ22             0.000000\nFQ23             0.000000\nFQ24            64.561164\nFQ35            76.127289\nFQ36            89.411320\nFQ25             0.000000\nFQ26             0.000000\nFQ27            97.049223\nFQ28            98.611290\nFQ29            22.623241\nFQ30            98.049721\nFQ31            99.198680\nFQ32            43.938919\nFQ33             0.001844\nFQ34            29.317817\nFQ37             0.000000\nTarget           0.000000\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Total missing values for each feature\n",
    "print (train.isnull().sum()/ len(train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Total    Percent\n",
       "FQ31  107577  99.198680\n",
       "FQ28  106940  98.611290\n",
       "FQ30  106331  98.049721\n",
       "FQ27  105246  97.049223\n",
       "FQ17   97099  89.536728\n",
       "FQ36   96963  89.411320\n",
       "FQ5    87261  80.464932\n",
       "FQ35   82557  76.127289\n",
       "FQ24   70014  64.561164\n",
       "FQ3    62228  57.381554\n",
       "FQ2    59322  54.701879\n",
       "FQ7    47826  44.101212\n",
       "FQ6    47787  44.065249\n",
       "FQ32   47650  43.938919\n",
       "FQ19   47407  43.714844\n",
       "FQ34   31794  29.317817\n",
       "FQ20   24679  22.756948\n",
       "FQ21   24635  22.716375\n",
       "FQ11   24570  22.656437\n",
       "FQ29   24534  22.623241"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FQ31</th>\n      <td>107577</td>\n      <td>99.198680</td>\n    </tr>\n    <tr>\n      <th>FQ28</th>\n      <td>106940</td>\n      <td>98.611290</td>\n    </tr>\n    <tr>\n      <th>FQ30</th>\n      <td>106331</td>\n      <td>98.049721</td>\n    </tr>\n    <tr>\n      <th>FQ27</th>\n      <td>105246</td>\n      <td>97.049223</td>\n    </tr>\n    <tr>\n      <th>FQ17</th>\n      <td>97099</td>\n      <td>89.536728</td>\n    </tr>\n    <tr>\n      <th>FQ36</th>\n      <td>96963</td>\n      <td>89.411320</td>\n    </tr>\n    <tr>\n      <th>FQ5</th>\n      <td>87261</td>\n      <td>80.464932</td>\n    </tr>\n    <tr>\n      <th>FQ35</th>\n      <td>82557</td>\n      <td>76.127289</td>\n    </tr>\n    <tr>\n      <th>FQ24</th>\n      <td>70014</td>\n      <td>64.561164</td>\n    </tr>\n    <tr>\n      <th>FQ3</th>\n      <td>62228</td>\n      <td>57.381554</td>\n    </tr>\n    <tr>\n      <th>FQ2</th>\n      <td>59322</td>\n      <td>54.701879</td>\n    </tr>\n    <tr>\n      <th>FQ7</th>\n      <td>47826</td>\n      <td>44.101212</td>\n    </tr>\n    <tr>\n      <th>FQ6</th>\n      <td>47787</td>\n      <td>44.065249</td>\n    </tr>\n    <tr>\n      <th>FQ32</th>\n      <td>47650</td>\n      <td>43.938919</td>\n    </tr>\n    <tr>\n      <th>FQ19</th>\n      <td>47407</td>\n      <td>43.714844</td>\n    </tr>\n    <tr>\n      <th>FQ34</th>\n      <td>31794</td>\n      <td>29.317817</td>\n    </tr>\n    <tr>\n      <th>FQ20</th>\n      <td>24679</td>\n      <td>22.756948</td>\n    </tr>\n    <tr>\n      <th>FQ21</th>\n      <td>24635</td>\n      <td>22.716375</td>\n    </tr>\n    <tr>\n      <th>FQ11</th>\n      <td>24570</td>\n      <td>22.656437</td>\n    </tr>\n    <tr>\n      <th>FQ29</th>\n      <td>24534</td>\n      <td>22.623241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent =total/len(train)*100\n",
    "pd.concat([total,percent], axis=1, keys=['Total','Percent']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ID               0.000000\ncountry_code     0.000000\nregion           0.000000\nage              0.277557\nFQ1              0.000000\nFQ2             55.244530\nFQ3             57.122878\nFQ4              0.000000\nFQ5             80.822773\nFQ6             44.320847\nFQ7             44.236934\nFQ8              0.000000\nFQ9              0.000000\nFQ10             0.000000\nFQ11            22.731674\nFQ12             0.000000\nFQ13             0.000000\nFQ14             0.000000\nFQ15             0.000000\nFQ16             0.000000\nFQ17            89.504486\nFQ18             0.000000\nFQ19            43.800159\nFQ20            22.497149\nFQ21            22.591820\nFQ22             0.000000\nFQ23             0.000000\nFQ24            64.358715\nFQ35            76.220496\nFQ36            89.457151\nFQ25             0.000000\nFQ26             0.000000\nFQ27            96.895239\nFQ28            98.642339\nFQ29            22.809131\nFQ30            98.115197\nFQ31            99.216817\nFQ32            44.058351\nFQ33             0.000000\nFQ34            28.704521\nFQ37             0.000000\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (test.isnull().sum()/ len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Total    Percent\n",
       "FQ31  107577  42.521624\n",
       "FQ28  106940  42.275418\n",
       "FQ30  106331  42.049499\n",
       "FQ27  105246  41.526658\n",
       "FQ17   97099  38.359183\n",
       "FQ36   96963  38.338897\n",
       "FQ5    87261  34.638438\n",
       "FQ35   82557  32.666027\n",
       "FQ24   70014  27.582391\n",
       "FQ3    62228  24.481309\n",
       "FQ2    59322  23.676300\n",
       "FQ7    47826  18.958744\n",
       "FQ6    47787  18.994707\n",
       "FQ32   47650  18.882209\n",
       "FQ19   47407  18.771555\n",
       "FQ34   31794  12.301975\n",
       "FQ20   24679   9.641665\n",
       "FQ21   24635   9.682238\n",
       "FQ11   24570   9.742176\n",
       "FQ29   24534   9.775372"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FQ31</th>\n      <td>107577</td>\n      <td>42.521624</td>\n    </tr>\n    <tr>\n      <th>FQ28</th>\n      <td>106940</td>\n      <td>42.275418</td>\n    </tr>\n    <tr>\n      <th>FQ30</th>\n      <td>106331</td>\n      <td>42.049499</td>\n    </tr>\n    <tr>\n      <th>FQ27</th>\n      <td>105246</td>\n      <td>41.526658</td>\n    </tr>\n    <tr>\n      <th>FQ17</th>\n      <td>97099</td>\n      <td>38.359183</td>\n    </tr>\n    <tr>\n      <th>FQ36</th>\n      <td>96963</td>\n      <td>38.338897</td>\n    </tr>\n    <tr>\n      <th>FQ5</th>\n      <td>87261</td>\n      <td>34.638438</td>\n    </tr>\n    <tr>\n      <th>FQ35</th>\n      <td>82557</td>\n      <td>32.666027</td>\n    </tr>\n    <tr>\n      <th>FQ24</th>\n      <td>70014</td>\n      <td>27.582391</td>\n    </tr>\n    <tr>\n      <th>FQ3</th>\n      <td>62228</td>\n      <td>24.481309</td>\n    </tr>\n    <tr>\n      <th>FQ2</th>\n      <td>59322</td>\n      <td>23.676300</td>\n    </tr>\n    <tr>\n      <th>FQ7</th>\n      <td>47826</td>\n      <td>18.958744</td>\n    </tr>\n    <tr>\n      <th>FQ6</th>\n      <td>47787</td>\n      <td>18.994707</td>\n    </tr>\n    <tr>\n      <th>FQ32</th>\n      <td>47650</td>\n      <td>18.882209</td>\n    </tr>\n    <tr>\n      <th>FQ19</th>\n      <td>47407</td>\n      <td>18.771555</td>\n    </tr>\n    <tr>\n      <th>FQ34</th>\n      <td>31794</td>\n      <td>12.301975</td>\n    </tr>\n    <tr>\n      <th>FQ20</th>\n      <td>24679</td>\n      <td>9.641665</td>\n    </tr>\n    <tr>\n      <th>FQ21</th>\n      <td>24635</td>\n      <td>9.682238</td>\n    </tr>\n    <tr>\n      <th>FQ11</th>\n      <td>24570</td>\n      <td>9.742176</td>\n    </tr>\n    <tr>\n      <th>FQ29</th>\n      <td>24534</td>\n      <td>9.775372</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "total_test = test.isnull().sum().sort_values(ascending=False)\n",
    "percent =total_test/len(train)*100\n",
    "pd.concat([total,percent], axis=1, keys=['Total','Percent']).head(20)"
   ]
  },
  {
   "source": [
    "Here you can clearly see that 7 columns have Null values higher than 80% so it is good to drop those columns from our data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ID', 'country_code', 'region', 'age', 'FQ1', 'FQ2', 'FQ3', 'FQ4',\n",
       "       'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13', 'FQ14',\n",
       "       'FQ15', 'FQ16', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22', 'FQ23', 'FQ24',\n",
       "       'FQ35', 'FQ25', 'FQ26', 'FQ29', 'FQ32', 'FQ33', 'FQ34', 'FQ37',\n",
       "       'Target'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train = train [train.columns[train.isnull().mean() < 0.80]]\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ID', 'country_code', 'region', 'age', 'FQ1', 'FQ2', 'FQ3', 'FQ4',\n",
       "       'FQ5', 'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13',\n",
       "       'FQ14', 'FQ15', 'FQ16', 'FQ17', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22',\n",
       "       'FQ23', 'FQ24', 'FQ35', 'FQ36', 'FQ25', 'FQ26', 'FQ27', 'FQ28', 'FQ29',\n",
       "       'FQ30', 'FQ31', 'FQ32', 'FQ33', 'FQ34', 'FQ37'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ6  FQ7  \\\n",
       "0       ID_000J8GTZ             1       6  35.0    2  NaN  NaN    2  NaN  1.0   \n",
       "1       ID_000QLXZM            32       7  70.0    2  NaN  NaN    2  NaN  1.0   \n",
       "2       ID_001728I2            71       7  22.0    2  1.0  NaN    2  NaN  1.0   \n",
       "3       ID_001R7IDN            48       3  27.0    1  NaN  NaN    2  2.0  NaN   \n",
       "4       ID_0029QKF8            25       0  79.0    2  NaN  NaN    2  NaN  NaN   \n",
       "...             ...           ...     ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "108441  ID_ZZYY7RTO           111       4  23.0    2  NaN  NaN    2  2.0  NaN   \n",
       "108442  ID_ZZYZTTC6            77       4  60.0    1  NaN  NaN    2  NaN  NaN   \n",
       "108443  ID_ZZZ3OW3S            42       2  59.0    1  NaN  1.0    1  NaN  1.0   \n",
       "108444  ID_ZZZLDXE8            57       7  79.0    1  NaN  NaN    2  1.0  NaN   \n",
       "108445  ID_ZZZMYW1F           110       2  74.0    2  1.0  2.0    2  1.0  1.0   \n",
       "\n",
       "        ...  FQ24  FQ35  FQ25  FQ26  FQ29  FQ32  FQ33  FQ34  FQ37  Target  \n",
       "0       ...   NaN   1.0     2     2   1.0   NaN   1.0   1.0     0       0  \n",
       "1       ...   NaN   NaN     1     1   2.0   NaN   1.0   2.0     0       0  \n",
       "2       ...   NaN   NaN     2     1   2.0   NaN   2.0   1.0     1       0  \n",
       "3       ...   NaN   NaN     2     2   NaN   2.0   1.0   1.0     1       0  \n",
       "4       ...   2.0   NaN     2     2   2.0   2.0   1.0   1.0     1       0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...     ...  \n",
       "108441  ...   2.0   NaN     2     2   NaN   NaN   1.0   NaN     1       0  \n",
       "108442  ...   NaN   NaN     2     2   NaN   NaN   1.0   1.0     1       0  \n",
       "108443  ...   NaN   NaN     2     2   2.0   2.0   1.0   2.0     1       1  \n",
       "108444  ...   NaN   NaN     2     2   2.0   NaN   1.0   1.0     1       0  \n",
       "108445  ...   2.0   NaN     2     2   1.0   NaN   1.0   NaN     1       1  \n",
       "\n",
       "[108446 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>...</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000J8GTZ</td>\n      <td>1</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_000QLXZM</td>\n      <td>32</td>\n      <td>7</td>\n      <td>70.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001728I2</td>\n      <td>71</td>\n      <td>7</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_001R7IDN</td>\n      <td>48</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0029QKF8</td>\n      <td>25</td>\n      <td>0</td>\n      <td>79.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108441</th>\n      <td>ID_ZZYY7RTO</td>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>ID_ZZYZTTC6</td>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>ID_ZZZ3OW3S</td>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>ID_ZZZLDXE8</td>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>ID_ZZZMYW1F</td>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108446 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train = train.dropna(thresh = 2)                # Apply dropna() function\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID  country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ5  FQ6  \\\n",
       "0      ID_000YI58E            39       2  22.0    2  NaN  NaN    2  NaN  1.0   \n",
       "1      ID_001SP4JF            30       2  62.0    1  NaN  NaN    2  NaN  1.0   \n",
       "2      ID_001VOF6S            65       4  35.0    2  1.0  NaN    1  1.0  NaN   \n",
       "3      ID_0030LULG           123       0  24.0    2  1.0  NaN    2  NaN  1.0   \n",
       "4      ID_0037PZ3R            67       2  25.0    2  NaN  NaN    1  NaN  NaN   \n",
       "...            ...           ...     ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "46472  ID_ZZYOTVBJ           112       3  38.0    1  1.0  NaN    2  NaN  NaN   \n",
       "46473  ID_ZZYSX122            82       2  77.0    2  1.0  1.0    2  NaN  1.0   \n",
       "46474  ID_ZZYXQDSD            93       5  26.0    2  NaN  NaN    2  NaN  1.0   \n",
       "46475  ID_ZZZH9SS4             6       7  59.0    2  1.0  NaN    2  NaN  1.0   \n",
       "46476  ID_ZZZTLL7U           105       0  24.0    2  NaN  NaN    2  1.0  NaN   \n",
       "\n",
       "       ...  FQ26  FQ27  FQ28  FQ29  FQ30  FQ31  FQ32  FQ33  FQ34  FQ37  \n",
       "0      ...     2   NaN   NaN   NaN   NaN   NaN   2.0   1.0   1.0     0  \n",
       "1      ...     2   NaN   NaN   2.0   NaN   1.0   1.0   1.0   1.0     0  \n",
       "2      ...     2   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN     0  \n",
       "3      ...     2   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "4      ...     2   NaN   NaN   1.0   NaN   NaN   NaN   2.0   1.0     1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "46472  ...     2   NaN   NaN   4.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "46473  ...     1   NaN   NaN   2.0   NaN   NaN   NaN   1.0   2.0     1  \n",
       "46474  ...     2   NaN   NaN   2.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "46475  ...     2   NaN   NaN   NaN   NaN   NaN   NaN   1.0   1.0     1  \n",
       "46476  ...     2   1.0   NaN   1.0   NaN   NaN   NaN   1.0   1.0     1  \n",
       "\n",
       "[46477 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ5</th>\n      <th>FQ6</th>\n      <th>...</th>\n      <th>FQ26</th>\n      <th>FQ27</th>\n      <th>FQ28</th>\n      <th>FQ29</th>\n      <th>FQ30</th>\n      <th>FQ31</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>39</td>\n      <td>2</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>30</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>65</td>\n      <td>4</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>123</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>67</td>\n      <td>2</td>\n      <td>25.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46472</th>\n      <td>ID_ZZYOTVBJ</td>\n      <td>112</td>\n      <td>3</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46473</th>\n      <td>ID_ZZYSX122</td>\n      <td>82</td>\n      <td>2</td>\n      <td>77.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46474</th>\n      <td>ID_ZZYXQDSD</td>\n      <td>93</td>\n      <td>5</td>\n      <td>26.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46475</th>\n      <td>ID_ZZZH9SS4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>59.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46476</th>\n      <td>ID_ZZZTLL7U</td>\n      <td>105</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>46477 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "test = test.dropna(thresh = 2)                # Apply dropna() function\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                  0\n",
       "country_code        0\n",
       "region              0\n",
       "age               322\n",
       "FQ1                 0\n",
       "FQ2             59321\n",
       "FQ3             62228\n",
       "FQ4                 0\n",
       "FQ6             47786\n",
       "FQ7             47825\n",
       "FQ8                 0\n",
       "FQ9                 0\n",
       "FQ10                0\n",
       "FQ11            24569\n",
       "FQ12                0\n",
       "FQ13                0\n",
       "FQ14                0\n",
       "FQ15                0\n",
       "FQ16                0\n",
       "FQ18                0\n",
       "FQ19            47406\n",
       "FQ20            24679\n",
       "FQ21            24635\n",
       "FQ22                0\n",
       "FQ23                0\n",
       "FQ24            70013\n",
       "FQ35            82556\n",
       "FQ25                0\n",
       "FQ26                0\n",
       "FQ29            24533\n",
       "FQ32            47649\n",
       "FQ33                0\n",
       "FQ34            31794\n",
       "FQ37                0\n",
       "Target              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "train.dropna(subset = ['FQ33'], axis = 0, how = 'any', inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ID                  0\n",
       "country_code        0\n",
       "region              0\n",
       "age               129\n",
       "FQ1                 0\n",
       "FQ2             25676\n",
       "FQ3             26549\n",
       "FQ4                 0\n",
       "FQ5             37564\n",
       "FQ6             20599\n",
       "FQ7             20560\n",
       "FQ8                 0\n",
       "FQ9                 0\n",
       "FQ10                0\n",
       "FQ11            10565\n",
       "FQ12                0\n",
       "FQ13                0\n",
       "FQ14                0\n",
       "FQ15                0\n",
       "FQ16                0\n",
       "FQ17            41599\n",
       "FQ18                0\n",
       "FQ19            20357\n",
       "FQ20            10456\n",
       "FQ21            10500\n",
       "FQ22                0\n",
       "FQ23                0\n",
       "FQ24            29912\n",
       "FQ35            35425\n",
       "FQ36            41577\n",
       "FQ25                0\n",
       "FQ26                0\n",
       "FQ27            45034\n",
       "FQ28            45846\n",
       "FQ29            10601\n",
       "FQ30            45601\n",
       "FQ31            46113\n",
       "FQ32            20477\n",
       "FQ33                0\n",
       "FQ34            13341\n",
       "FQ37                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "test.dropna(subset = ['FQ33'], axis = 0, how = 'any', inplace = True)\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop (['ID'], axis = 1)\n",
    "test = test.drop(['ID','FQ5', 'FQ17', 'FQ36', 'FQ27', 'FQ28', 'FQ30', 'FQ31'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((108444, 34), (46477, 33))"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        country_code  region   age  FQ1  FQ2  FQ3  FQ4  FQ6  FQ7  FQ8  ...  \\\n",
       "0                  1       6  35.0    2  NaN  NaN    2  NaN  1.0    2  ...   \n",
       "1                 32       7  70.0    2  NaN  NaN    2  NaN  1.0    2  ...   \n",
       "2                 71       7  22.0    2  1.0  NaN    2  NaN  1.0    2  ...   \n",
       "3                 48       3  27.0    1  NaN  NaN    2  2.0  NaN    2  ...   \n",
       "4                 25       0  79.0    2  NaN  NaN    2  NaN  NaN    2  ...   \n",
       "...              ...     ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "108441           111       4  23.0    2  NaN  NaN    2  2.0  NaN    1  ...   \n",
       "108442            77       4  60.0    1  NaN  NaN    2  NaN  NaN    2  ...   \n",
       "108443            42       2  59.0    1  NaN  1.0    1  NaN  1.0    2  ...   \n",
       "108444            57       7  79.0    1  NaN  NaN    2  1.0  NaN    2  ...   \n",
       "108445           110       2  74.0    2  1.0  2.0    2  1.0  1.0    2  ...   \n",
       "\n",
       "        FQ23  FQ24  FQ35  FQ25  FQ26  FQ29  FQ32  FQ33  FQ34  FQ37  \n",
       "0          2   NaN   1.0     2     2   1.0   NaN   1.0   1.0     0  \n",
       "1          2   NaN   NaN     1     1   2.0   NaN   1.0   2.0     0  \n",
       "2          2   NaN   NaN     2     1   2.0   NaN   2.0   1.0     1  \n",
       "3          2   NaN   NaN     2     2   NaN   2.0   1.0   1.0     1  \n",
       "4          1   2.0   NaN     2     2   2.0   2.0   1.0   1.0     1  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "108441     2   2.0   NaN     2     2   NaN   NaN   1.0   NaN     1  \n",
       "108442     2   NaN   NaN     2     2   NaN   NaN   1.0   1.0     1  \n",
       "108443     2   NaN   NaN     2     2   2.0   2.0   1.0   2.0     1  \n",
       "108444     2   NaN   NaN     2     2   2.0   NaN   1.0   1.0     1  \n",
       "108445     2   2.0   NaN     2     2   1.0   NaN   1.0   NaN     1  \n",
       "\n",
       "[108444 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>region</th>\n      <th>age</th>\n      <th>FQ1</th>\n      <th>FQ2</th>\n      <th>FQ3</th>\n      <th>FQ4</th>\n      <th>FQ6</th>\n      <th>FQ7</th>\n      <th>FQ8</th>\n      <th>...</th>\n      <th>FQ23</th>\n      <th>FQ24</th>\n      <th>FQ35</th>\n      <th>FQ25</th>\n      <th>FQ26</th>\n      <th>FQ29</th>\n      <th>FQ32</th>\n      <th>FQ33</th>\n      <th>FQ34</th>\n      <th>FQ37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32</td>\n      <td>7</td>\n      <td>70.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71</td>\n      <td>7</td>\n      <td>22.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>0</td>\n      <td>79.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108441</th>\n      <td>111</td>\n      <td>4</td>\n      <td>23.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108442</th>\n      <td>77</td>\n      <td>4</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108443</th>\n      <td>42</td>\n      <td>2</td>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108444</th>\n      <td>57</td>\n      <td>7</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108445</th>\n      <td>110</td>\n      <td>2</td>\n      <td>74.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108444 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "y = train.Target\n",
    "X = train.drop('Target', axis=1)\n",
    "#X = X.select_dtypes(exclude=['object'])\n",
    "\n",
    "X"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=999)"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "X.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Impute training and test data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "train = imputer.fit_transform(X)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scale training and test data\n",
    "scaler = MinMaxScaler()\n",
    "train = scaler.fit_transform(X)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Mean accurracy: 0.591 std: 0.004'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline ([('impute', imputer), ('model', dt_model)])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "'Mean accurracy: {} std: {}'.format(round(np.mean(scores), 3), round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "predictions = pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID  Target\n",
       "0  ID_000YI58E       0\n",
       "1  ID_001SP4JF       0\n",
       "2  ID_001VOF6S       0\n",
       "3  ID_0030LULG       0\n",
       "4  ID_0037PZ3R       0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_000YI58E</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_001SP4JF</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_001VOF6S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_0030LULG</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_0037PZ3R</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_Tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=10,\n",
    "                               n_jobs = -1)\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, trainData, trainTarget, cv=10, scoring=scorer)\n",
    "print('10 Fold Cross Validation F1 Score = {} with std = {}'.format(round(cv_score.mean(), 4), round(cv_score.std(), 4)))"
   ]
  },
  {
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "#define imputer\n",
    "imputer = IterativeImputer()\n",
    "#fit on the dataset\n",
    "imputer.fit(X)\n",
    "#transform the dataset\n",
    "X_imputed = imputer.transform(X)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "test = pd.get_dummies(test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan)\n",
    "X_imputed = imputer.fit_transform(X_train.values)\n",
    "imputed_X_test = imputer.transform(X_test.values)\n",
    "print(\"Imputed data:\")\n",
    "print(X_imputed)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan)\n",
    "\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_test = pd.DataFrame(imputer.transform(X_test))\n",
    "imputed_test = pd.DataFrame(imputer.transform(test))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_test.columns = X_test.columns\n",
    "imputed_test.columns = test.columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (imputed_X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print((imputed_X_train, imputed_X_test, y_train, y_test))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "#define imputer\n",
    "imputer = IterativeImputer()\n",
    "#fit on the dataset\n",
    "imputer.fit(X_train)\n",
    "#transform the dataset\n",
    "X_trainB = imputer.transform(X_train)\n",
    "X_testB = imputer.transform(X_test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Itlearns about the data and does nothing else\n",
    "my_imputer.fit(X_train)\n",
    "\n",
    "#Calling transform to apply the learnt information on supplied data\n",
    "X_train_new = my_imputer.transform(X_train)\n",
    "X_test_new = my_imputer.transform(X_test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "\n",
    "\n",
    "X_imputed = imputer.fit_transform(dfstd['marks'].values.reshape(-1,1))[:,0]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X = pd.DataFrame(imputer.fit_transform(X),columns = X.columns)\n",
    "X.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Initialize KNNImputer\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "#Impute/Fill Missing values of each feature\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform (X_train, y_train),  columns= X.columns)\n",
    "\n",
    "results = imputer.transform (X_test)\n",
    "\n",
    "results.shape\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Initialize KNNImputer\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "#Impute/Fill Missing values of each feature\n",
    "X_imputed = imputer.fit_transform (X)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline ([('impute', imputer), ('model', dt_model)])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "'Mean accurracy: {} std: {}'.format(round(np.mean(scores), 3), round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "pipeline.fit(imputed_X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "predictions = pipeline.predict(imputed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (imputed_X_test.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = predictions"
   ]
  },
  {
   "source": [
    "submission = pd.DataFrame({'Target':predictions})"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "source": [
    "output = pd.DataFrame({'ID': test.ID, 'Target': predictions})"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "my_model = XGBRegressor()\n",
    "my_model.fit(X_train, y_train)\n",
    "#validate model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "predictions = my_model.predict(X_valid)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('submission_Tree.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Make new prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_imputed.shape)\n",
    "print(y_train.shape)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Instantiate model and fit to data\n",
    "dt_model.fit(X, y)\n",
    "#Make predictions and store in 'Survived' column of df_test\n",
    "Y_pred = dt_model.predict(imputed_X_test)\n",
    "test['Survived'] = Y_pred"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "dt_model.fit(X_imputed, y_train)\n",
    "predictions = dt_model.predict(imputed_X_test)\n",
    "\n",
    "test['Target'] = predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "dt_model = dt_model.fit(X_imputed, y)\n",
    "y_predict = dt_model.predict(imputed_X_test)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Make predictions and store in 'Survived' column of df_test\n",
    "test['Target'] = y_predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df.apply(lambda col: col.drop_duplicates().reset_index(drop=True))\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape, y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ID = test['ID']\n",
    "submission_df = pd.DataFrame({\n",
    "                  \"ID\": sub_ID, \n",
    "                  \"Target\": y_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID = test['ID']\n",
    "submission_df = pd.DataFrame({\n",
    "                  \"ID\": test.ID, \n",
    "                  \"Target\": y_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(imputed_X_train, y_train)\n",
    "y_pred = clf.predict(imputed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_1.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor()\n",
    "xgbr = xgbr.fit(X, y)\n",
    "pred_values = xgbr.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model = dt_model.fit (X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model score: %.3f\" % dt_model.score(X_testB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "predicted_proba = dt_model.predict_proba(X_testB)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = f1_score(y_test, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= dt_model.predict(X_testB)\n",
    "print('Score', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= dt_model.predict(X_testB)\n",
    "print('Score', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "predicted_proba = dt_model.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = f1_score(y_test, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= rf.predict(val_x)\n",
    "print('Score', f1_score(val_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = clf.predict (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['ID', 'FQ5', 'FQ17', 'FQ36', 'FQ27', 'FQ28', 'FQ30', 'FQ31'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "rf_model.fit(X_imputed, y)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ID': test.ID, 'Target': y_pred})\n",
    "output.to_csv('submission_RF2.csv', index=False)"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "train.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imputing Missing Data Using Sklearn SimpleImputer\n",
    "SimpleImputer is a class found in package sklearn.impute. It is used to impute / replace the numerical or categorical missing data related to one or more features with appropriate values. \n",
    "https://dzone.com/articles/imputing-missing-data-using-sklearn-simpleimputer\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There are two columns / features (one numerical - marks, and another categorical - gender) which are having missing values and need to be imputed. In the code below, an instance of SimpleImputer is created with strategy as \"mean\". The missing value is represented using NaN. Note some of the following:\n",
    "\n",
    "sklearn.impute package is used for importing SimpleImputer class.\n",
    "SimpleImputer takes two argument such as missing_values and strategy.\n",
    "fit_transform method is invoked on the instance of SimpleImputer to impute the missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imputation Approach with KNNImputer\n",
    "We will use the KNNImputer function from the impute module of the sklearn. KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#KNN based imputation for categorical variables\n",
    "imputer = KNNImputer (n_neighbors = 2)\n",
    "\n",
    "\n",
    "imputed_train = imputer.fit_transform(train[['country_code', 'region', 'age', 'FQ1', 'FQ2', 'FQ3', 'FQ4','FQ5', 'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13','FQ14', 'FQ15', 'FQ16', 'FQ17', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22','FQ23', 'FQ24', 'FQ35', 'FQ36', 'FQ25', 'FQ26', 'FQ27', 'FQ28', 'FQ29','FQ30', 'FQ31', 'FQ32', 'FQ33', 'FQ34', 'FQ37']])\n",
    "\n",
    "#print the completed dataframe\n",
    "imputed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "  \n",
    "# Imputer object using the mean strategy and \n",
    "# missing_values type for imputation\n",
    "imputer = SimpleImputer(missing_values = np.nan, \n",
    "                        strategy ='mean')\n",
    "  \n",
    "# Fitting the data to the imputer object\n",
    "imputer = imputer.fit(train)\n",
    "  \n",
    "# Imputing the data     \n",
    "imputed_train = imputer.transform(train)\n",
    "  \n",
    "print(\"Imputed Data : \\n\", imputed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Missing values is represented using NaN and hence specified. If it is empty field, missing values will be specified as:\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "\n",
    "dfstd.marks = imputer.fit_transform(dfstd['marks'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "dfstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "To drop all rows with 'any' NAs in a particular column, I used .dropna() and specified the subset = column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset = ['FQ33'], axis = 0, how = 'any', inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=\"cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Distribution\n",
    "target_counts = train.groupby('Target').size()\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "You can see that there are nearly triple the number of observations with target 0 than there are with target 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examine Target Column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sns.countplot(x = 'Target',data = train)\n",
    "sizes=[]\n",
    "for p in s.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    s.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/len(train)*100),\n",
    "            ha=\"center\", fontsize=14) "
   ]
  },
  {
   "source": [
    "## Create Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "sns.pairplot(train, hue='Target', size=1.5);"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first three rows\n",
    "train.iloc[1:4]"
   ]
  },
  {
   "source": [
    "## Replace Multiple Values in Multiple Columns\n",
    "\n",
    "Target Category:\n",
    "- 1: Yes\n",
    "- 2: No\n",
    "- 3: Don’t know \n",
    "- 4: Refused to answer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.count()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.replace({'FQ1': {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ2' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ3' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ4' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ5' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ6'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ7' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ8' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ9' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ10' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ11'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ12' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ13'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ14' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ15' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ16' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ17' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ18' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ19' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ20' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ21' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ22' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ23' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ24' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ35' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ36'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ25'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ26' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ27' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ28' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ29' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'},\n",
    "'FQ30'{1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ31' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ32' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ33' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ34' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}, \n",
    "'FQ37' {1: 'Yes', 2: 'No', 3: 'Don’t know', 4: 'Refused to answer'}})"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train.columns"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique values\n",
    "train['country_code'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, value_counts will display all unique values with the number of times each value appears:\n",
    "# Show counts\n",
    "train['country_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique values\n",
    "train['region'].value_counts()"
   ]
  },
  {
   "source": [
    "Both unique and value_counts are useful for manipulating and exploring categorical\n",
    "columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FQ1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FQ4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change multiple columns with float to int\n",
    "train[['FQ1', 'FQ2', 'FQ3', 'FQ4',\n",
    "       'FQ5', 'FQ6', 'FQ7', 'FQ8', 'FQ9', 'FQ10', 'FQ11', 'FQ12', 'FQ13',\n",
    "       'FQ14', 'FQ15', 'FQ16', 'FQ17', 'FQ18', 'FQ19', 'FQ20', 'FQ21', 'FQ22',\n",
    "       'FQ23', 'FQ24', 'FQ35', 'FQ36', 'FQ25', 'FQ26', 'FQ27', 'FQ28', 'FQ29',\n",
    "       'FQ30', 'FQ31', 'FQ32', 'FQ33', 'FQ34', 'FQ37']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}